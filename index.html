<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jinbao Wang (ÁéãÈáëÂÆù)</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jinbao Wang</name>
              </p>
              <p>I am a Research Assistant Professor at <a href="https://www.sustech.edu.cn">Southern University of Science and Technology (SUSTech)</a>, where I work on image anomaly detection, computer vision and machine learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:linkingring@163.com">Email</a> &nbsp/&nbsp
                <a href="data/Jinbao_Wang_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/Jinbao-Wang-Bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=qI80ipUAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/jinbao-wang">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Jinbao-Wang.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/Jinbao-Wang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading> <b>Research</b></heading>
              <p>
                I'm interested in image anomaly detection, graph representation learning, computer vision, and machine learning.
                Much of my research is about detecting and localize anomalies from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
              <p>Note that *contributed equally, ‚Ä†corresponding author</p>
            </td>
          </tr>
        </tbody> </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <!-- Image Anomaly Detection -->
    <tr onmouseout="graphcore_stop()" onmouseover="graphcore_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <!-- <div class="two" id='graphcore_image'>
            <video  width=100% height=100% muted autoplay loop>
          <source src="images/bakedsdf_after.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video>
        </div> -->
          <img src='images/graphcore.png' width="160">
        </div>
        <script type="text/javascript">
          function graphcore_start() {
            document.getElementById('graphcore_image').style.opacity = "1";
          }
          function graphcore_stop() {
            document.getElementById('graphcore_image').style.opacity = "0";
          }
          graphcore_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2301.12082.pdf">
          <papertitle>Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore</papertitle>
        </a>
        <br>
        Guoyang Xie*, <strong>Jinbao Wang</strong>*‚Ä†, Jiaqi Liu*, Feng Zheng‚Ä†, Yaochu Jin
        <br>
        <em>International Conference on Learning Representations (ICLR)</em>, 2023
        <br>
        <a href="https://github.com/M-3LAB/open-iad">project page</a>
        /
        <a href="https://arxiv.org/pdf/2301.12082.pdf">arXiv</a>
        <p></p>
        <p>
          We reveal that rotation-invariant feature property has a significant impact in industrial-based fewshot anomaly detection.
        </p>
      </td>
    </tr>

    <tr onmouseout="imiad_stop()" onmouseover="imiad_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/imiad.png' width="160">
        </div>
        <script type="text/javascript">
          function imiad_start() {
            document.getElementById('imiad_image').style.opacity = "1";
          }
          function imiad_stop() {
            document.getElementById('imiad_image').style.opacity = "0";
          }
          imiad_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2301.13359.pdf">
          <papertitle>IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing</papertitle>
        </a>
        <br>
        Guoyang Xie*, <strong>Jinbao Wang</strong>*, Jiaqi Liu*, Jiayi Lyu, Yong Liu, Chengjie Wang, Feng Zheng, Yaochu Jin
        <br>
        <em>IEEE Transactions on Cybernetics (IEEE TCYB) (Major Revision)</em>, 2023
        <br>
        <a href="https://github.com/M-3LAB/open-iad">project page</a>
        /
        <a href="https://arxiv.org/pdf/2301.13359.pdf">arXiv</a>
        /
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">impact factor</a>
        <p></p>
        <p>
          We propose a large-scale systematic benchmark and uniform setting for IAD to bridge the gap between academy and industrial manufacturing 
        </p>
      </td>
    </tr>

    <tr onmouseout="iadsurvey_stop()" onmouseover="iadsurvey_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/iadsurvey.png' width="160">
        </div>
        <script type="text/javascript">
          function iadsurvey_start() {
            document.getElementById('iadsurvey_image').style.opacity = "1";
          }
          function iadsurvey_stop() {
            document.getElementById('iadsurvey_image').style.opacity = "0";
          }
          iadsurvey_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2301.11514.pdf">
          <papertitle>Deep Industrial Image Anomaly Detection: A Survey</papertitle>
        </a>
        <br>
        Jiaqi Liu*, Guoyang Xie*, <strong>Jinbao Wang</strong>*, Shangnian Li, Chengjie Wang, Feng Zheng, Yaochu Jin
        <br>
        <em>Machine Intelligence Research (MIR)</em>, 2023
        <br>
        <a href="https://github.com/M-3LAB/awesome-industrial-anomaly-detection">project page</a>
        /
        <a href="https://arxiv.org/pdf/2301.11514.pdf">arXiv</a>
        <p></p>
        <p>
          We provide a comprehensive review of deep learning-based IAD from the perspectives of neural network architectures, levels of supervision, loss functions, metrics and datasets. 
        </p>
      </td>
    </tr>

    <tr onmouseout="cvprw_stop()" onmouseover="cvprw_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/cvprw.png' width="160">
        </div>
        <script type="text/javascript">
          function cvprw_start() {
            document.getElementById('cvprw_image').style.opacity = "1";
          }
          function cvprw_stop() {
            document.getElementById('cvprw_image').style.opacity = "0";
          }
          cvprw_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2304.03294.pdf">
          <papertitle>What Makes a Good Data Augmentation for Few-Shot Unsupervised Image Anomaly Detection</papertitle>
        </a>
        <br>
        Lingrui Zhang, Shuheng Zhang, Guoyang Xie, Jiaqi Liu, Hua Yan, <strong>Jinbao Wang</strong>‚Ä†, Feng Zheng‚Ä†, Yaochu Jin
        <br>
        <em>CVPR VISION Workshop (CVPRW)</em>, 2023
        <br>
        <a href="https://arxiv.org/pdf/2304.03294.pdf">arXiv</a>
        <p></p>
        <p>
          We systematically investigate various data augmentation methods for few-shot IAD algorithms.  
        </p>
      </td>
    </tr>

    <tr onmouseout="softpatch_stop()" onmouseover="softpatch_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/softpatch.png' width="160">
        </div>
        <script type="text/javascript">
          function softpatch_start() {
            document.getElementById('softpatch_image').style.opacity = "1";
          }
          function softpatch_stop() {
            document.getElementById('softpatch_image').style.opacity = "0";
          }
          softpatch_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/pdf?id=pIYYJflkhZ">
          <papertitle>SoftPatch: Unsupervised Anomaly Detection with Noisy Data</papertitle>
        </a>
        <br>
        Xi Jiang, Jianlin Liu, <strong>Jinbao Wang</strong>‚Ä†, Qiang Nie, W. U. Kai, Yong Liu, Chengjie Wang, Feng Zheng‚Ä†
        <br>
        <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022
        <br>
        <a href="https://github.com/M-3LAB/open-iad">project page</a>
        /
        <a href="https://openreview.net/pdf?id=pIYYJflkhZ">openreview</a>
        <p></p>
        <p>
          we proposed a memory-based unsupervised AD method, which efficiently denoises the data at the patch level.
        </p>
      </td>
    </tr>

    <tr onmouseout="continualad_stop()" onmouseover="continualad_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/continualad.png' width="160">
        </div>
        <script type="text/javascript">
          function continualad_start() {
            document.getElementById('continualad_image').style.opacity = "1";
          }
          function continualad_stop() {
            document.getElementById('continualad_image').style.opacity = "0";
          }
          continualad_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2201.12589.pdf">
          <papertitle>Towards Continual Adaptation in Industrial Anomaly Detection</papertitle>
        </a>
        <br>
        Wujin Li, Jiawei Zhan, <strong>Jinbao Wang</strong>‚Ä†, Bizhong Xia, Bin-Bin Gao, Jun Liu, Chengjie Wang, and Feng Zheng‚Ä†
        <br>
        <em>ACM Multimedia (ACM MM)</em>, 2022
        <br>
        <a href="https://github.com/M-3LAB/open-iad">project page</a>
        /
        <a href="https://openreview.net/pdf?id=pIYYJflkhZ">openreview</a>
        <p></p>
        <p>
          we proposed a proposes a unified framework by incorporating continual learning to achieve our newly designed task of continual anomaly detection.
        </p>
      </td>
    </tr>

  <!-- Federated Learning Medical -->
    <tr onmouseout="fedmedgan_stop()" onmouseover="fedmedgan_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/fedmedgan.png' width="160">
        </div>
        <script type="text/javascript">
          function fedmedgan_start() {
            document.getElementById('fedmedgan_image').style.opacity = "1";
          }
          function fedmedgan_stop() {
            document.getElementById('fedmedgan_image').style.opacity = "0";
          }
          fedmedgan_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231223004058?via%3Dihub">
          <papertitle>FedMed-GAN: Misaligned Unpaired Brain Image Synthesis via Transform Loss</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>*, Guoyang Xie*, Yawen Huang*, Jiayi Lyu, Feng Zheng, Yefeng Zheng, Yaochu Jin
        <br>
        <em>Neurocomputing</em>, 2023
        <br>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231223004058?via%3Dihub">sciencedirect</a>
        /
        <a href="https://arxiv.org/pdf/2201.08953.pdf">arXiv</a>
        /
        <a href="https://www.sciencedirect.com/journal/neurocomputing">impact factor</a>
        <p></p>
        <p>
          We proposed a new benchmark for federated domain translation on unsupervised brain image synthesis to bridge the gap between federated learning and medical GAN.     
        </p>
      </td>
    </tr>

    <tr onmouseout="fedmedatl_stop()" onmouseover="fedmedatl_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/fedmedatl.png' width="160">
        </div>
        <script type="text/javascript">
          function fedmedatl_start() {
            document.getElementById('fedmedatl_image').style.opacity = "1";
          }
          function fedmedatl_stop() {
            document.getElementById('fedmedatl_image').style.opacity = "0";
          }
          fedmedatl_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2201.12589.pdf">
          <papertitle>FedMed-ATL: Misaligned Unpaired Brain Image Synthesis via Transform Loss</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>*, Guoyang Xie*, Yawen Huang*, Yefeng Zheng, Yaochu Jin, Feng Zheng
        <br>
        <em>ACM Multimedia (ACM MM)</em>, 2023
        <br>
        <a href="https://arxiv.org/pdf/2201.12589.pdf">arXiv</a>
        <p></p>
        <p>
          We proposed a method that reducing the demands for deformable registration while encouraging to leverage the misaligned and unpaired data   
        </p>
      </td>
    </tr>

    <tr onmouseout="medgansurvey_stop()" onmouseover="medgansurvey_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/medgansurvey.png' width="160">
        </div>
        <script type="text/javascript">
          function medgansurvey_start() {
            document.getElementById('medgansurvey_image').style.opacity = "1";
          }
          function medgansurvey_stop() {
            document.getElementById('medgansurvey_image').style.opacity = "0";
          }
          medgansurvey_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2202.06997.pdf">
          <papertitle>Cross-Modality Neuroimage Synthesis: A Survey</papertitle>
        </a>
        <br>
        Guoyang Xie*, <strong>Jinbao Wang</strong>*, Yawen Huang*, Jiayi Lyu, Feng Zheng, Yaochu Jin
        <br>
        <em>ACM Computing Survey (Major Revision)</em>, 2023
        <br>
        <a href="https://arxiv.org/pdf/2202.06997.pdf">arXiv</a>
        /
        <a href="https://dl.acm.org/journal/csur">impact factor</a>
        <p></p>
        <p>
          We provide a comprehensive review of cross-modality synthesis for neuroimages, from the perspectives of weakly-supervised and unsupervised settings, loss functions, evaluation metrics, ranges of modality, datasets, and the synthesis-based downstream applications.     
        </p>
      </td>
    </tr>

  <!-- Fast Retrieval -->
    <tr onmouseout="ccmh_stop()" onmouseover="ccmh_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/ccmh.png' width="160">
        </div>
        <script type="text/javascript">
          function ccmh_start() {
            document.getElementById('ccmh_image').style.opacity = "1";
          }
          function ccmh_stop() {
            document.getElementById('ccmh_image').style.opacity = "0";
          }
          ccmh_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323003631">
          <papertitle>Continuous Cross-Modal Hashing</papertitle>
        </a>
        <br>
        Zheng Hao*, <strong>Jinbao Wang</strong>*, Jinbao Wang, Xiantong Zhen, Jingkuan Song, Feng Zheng, Ke Lu, Guo-Jun Qi
        <br>
        <em> Pattern Recognition (PR) </em>, 2023
        <br>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323003631">sciencedirect</a>
        /
        <a href="https://www.sciencedirect.com/journal/pattern-recognition">imapct factor</a> 
        <p></p>
        <p>
          We propose a novel framework for the new task of continuous cross-modal hashing.
        </p>
      </td>
    </tr>

    <tr onmouseout="hgnn_stop()" onmouseover="hgnn_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/hgnn.png' width="160">
        </div>
        <script type="text/javascript">
          function hgnn_start() {
            document.getElementById('hgnn_image').style.opacity = "1";
          }
          function hgnn_stop() {
            document.getElementById('hgnn_image').style.opacity = "0";
          }
          hgnn_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9474952">
          <papertitle>Learning Efficient Hash Codes for Fast Graph-Based Data Similarity Retrieval</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>, Shuo Xu, Feng Zheng, Ke Lu, Jingkuan Song, and Ling Shao 
        <br>
        <em>IEEE Transactions on Image Processing (IEEE TIP) </em>, 2021
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/9474952">ieeexplore</a>
        /
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">impact factor</a>
        <p></p>
        <p>
          To represent graph-based data, and maintain fast retrieval while doing so, we introduce an efficient hash model with graph neural networks for fast graph-based data retrieval.
        </p>
      </td>
    </tr>

    <tr onmouseout="tamnas_stop()" onmouseover="tamnas_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/tamnas.png' width="160">
        </div>
        <script type="text/javascript">
          function tamnas_start() {
            document.getElementById('tamnas_image').style.opacity = "1";
          }
          function tamnas_stop() {
            document.getElementById('tamnas_image').style.opacity = "0";
          }
          tamnas_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2103.00363.pdf">
          <papertitle>Tiny Adversarial Multi-Objective Oneshot Neural Architecture Search</papertitle>
        </a>
        <br>
        Guoyang Xie*, <strong>Jinbao Wang</strong>*, Guo Yu, Jiayi Lyu, Feng Zheng, Yaochu Jin 
        <br>
        <em>Complex & Intelligent System (CIS)</em>, 2023
        <br>
        <a href="https://link.springer.com/article/10.1007/s40747-023-01139-8">springer</a>
        /
        <a href="https://www.springer.com/journal/40747">impact factor</a>
        <p></p>
        <p>
          We propose a multi-objective oneshot network architecture search algorithm to obtain the best trade-off networks in terms of the adversarial accuracy, the clean accuracy and the model size.      
        </p>
      </td>
    </tr>

  <!-- Human Pose -->
    <tr onmouseout="posesurvey_stop()" onmouseover="posesurvey_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/posesurvey.png' width="160">
        </div>
        <script type="text/javascript">
          function posesurvey_start() {
            document.getElementById('posesurvey_image').style.opacity = "1";
          }
          function posesurvey_stop() {
            document.getElementById('posesurvey_image').style.opacity = "0";
          }
          posesurvey_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/pii/S1077314221000692">
          <papertitle>Deep 3D Human Pose Estimation: A Review</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>*, Shujie Tan*, Xiantong Zhen, Shuo Xu, Feng Zheng, Zhenyu He, and Ling Shao
        <br>
        <em>Computer Vision and Image Understanding (CVIU)</em>, 2021
        <br>
        <a href="https://www.sciencedirect.com/science/article/pii/S1077314221000692">sciencedirect</a>
        /
        <a href="https://www.sciencedirect.com/journal/computer-vision-and-image-understanding">impact factor</a>
        <p></p>
        <p>
          The recent methods for deep 3D pose estimation are categorized and thoroughly analyzed. Provide an extensive review of related datasets and evaluation metrics. Compare the pros and cons of the deep 3D models valuated on the datasets and draw a conclusion.
        </p>
      </td>
    </tr>

    <tr onmouseout="motioncapture_stop()" onmouseover="motioncapture_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/motioncapture.png' width="160">
        </div>
        <script type="text/javascript">
          function motioncapture_start() {
            document.getElementById('motioncapture_image').style.opacity = "1";
          }
          function motioncapture_stop() {
            document.getElementById('motioncapture_image').style.opacity = "0";
          }
          motioncapture_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/8683506">
          <papertitle>A Markerless Body Motion Capture System for Character Animation Based on Multi-view Cameras</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>, Ke Lu, Jian Xue, Pengcheng Gao, Yanfu Yan
        <br>
        <em>IEEE International Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP)</em>, 2019
        <br>
        <a href="https://github.com/jinbao-wang/skinmesh">project page</a>
        /
        <a href="https://ieeexplore.ieee.org/abstract/document/8683506">ieeexplore</a>
        /
        <a href="https://arxiv.org/abs/2212.05788">arXiv</a> 
        <p></p>
        <p>
          A novel application system is proposed to achieve the generation of 3D character animation driven by markerless human body motion capture.
        </p>
      </td>
    </tr>

  <!-- image propcessing -->
    <tr onmouseout="clickseg_stop()" onmouseover="clickseg_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/clickseg.png' width="160">
        </div>
        <script type="text/javascript">
          function clickseg_start() {
            document.getElementById('clickseg_image').style.opacity = "1";
          }
          function clickseg_stop() {
            document.getElementById('clickseg_image').style.opacity = "0";
          }
          clickseg_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Seminar_Learning_for_Click-Level_Weakly_Supervised_Semantic_Segmentation_ICCV_2021_paper.html">
          <papertitle>Seminar Learning for Click-Level Weakly Supervised Semantic Segmentation</papertitle>
        </a>
        <br>
        Hongjun Chen,<strong>Jinbao Wang</strong>, Hong Cai Chen, Xiantong Zhen, Feng Zheng, Rongrong Ji, Ling Shao
        <br>
        <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2021
        <br>
        <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Seminar_Learning_for_Click-Level_Weakly_Supervised_Semantic_Segmentation_ICCV_2021_paper.pdf">openaccess</a>
        /
        <a href="https://arxiv.org/abs/2108.13393">arXiv</a> 
        <p></p>
        <p>
          We propose seminar learning, a new learning paradigm for semantic segmentation with click-level supervision.
        </p>
      </td>
    </tr>

    <tr onmouseout="dehazemsrcr_stop()" onmouseover="dehazemsrcr_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/dehazemsrcr.png' width="160">
        </div>
        <script type="text/javascript">
          function dehazemsrcr_start() {
            document.getElementById('dehazemsrcr_image').style.opacity = "1";
          }
          function dehazemsrcr_stop() {
            document.getElementById('dehazemsrcr_image').style.opacity = "0";
          }
          dehazemsrcr_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/7984895">
          <papertitle>Single Image Dehazing Based on the Physical Model and MSRCR Algorithm</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>, Ke Lu, Jian Xue, Ning He, Ling Shao
        <br>
        <em>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)</em>, 2017
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/7984895">ieeexplore</a>
        /
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">impact factor</a>
        <p></p>
        <p>
          We propose a single image dehazing method based on a physical model and the brightness components of the image by using a multi-scale retinex with color restoration algorithm.
        </p>
      </td>
    </tr>

    <tr onmouseout="dehazedcp_stop()" onmouseover="dehazedcp_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <img src='images/dehazedcp.png' width="160">
        </div>
        <script type="text/javascript">
          function dehazedcp_start() {
            document.getElementById('dehazedcp_image').style.opacity = "1";
          }
          function dehazedcp_stop() {
            document.getElementById('dehazedcp_image').style.opacity = "0";
          }
          dehazedcp_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231214010157">
          <papertitle>Single Image Dehazing with a Physical Model and Dark Channel Prior</papertitle>
        </a>
        <br>
        <strong>Jinbao Wang</strong>, Ning He, Lu-Lu Zhang, Ke Lu 
        <br>
        <em>Neurocomputing</em>, 2015 &nbsp <font color="red"><strong>(Highly Cited Paper)</strong></font>
        <br>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231214010157">sciencedirect</a>
        /
        <a href="https://kd.nsfc.gov.cn/paperDownload/1000018804437.pdf">nsfc</a> 
        /
        <a href="https://www.sciencedirect.com/journal/neurocomputing">impact factor</a>
        <p></p>
        <p>
          We propose a single image dehazing method that is based on a physical model and the dark channel prior principle.
        </p>
      </td>
    </tr>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading><b> Publication List</b></heading>
        <p> <b> Conference </b></p>
        <ol>
          <li>
            Lingrui Zhang, Shuheng Zhang, Guoyang Xie, Jiaqi Liu, Hua Yan, <strong>Jinbao Wang</strong>‚Ä†, Feng Zheng‚Ä†, and Yaochu Jin. 
            "What makes a good data augmentation for few-shot unsupervised image anomaly detection?" 
            In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR Vision Workshop), pp. 4344-4353. 2023.
          </li>
          <li>
            Guoyang Xie*, <strong>Jinbao Wang</strong>*‚Ä†, Jiaqi Liu*, Feng Zheng‚Ä†, and Yaochu Jin. 
            "Pushing the limits of fewshot anomaly detection in industry vision: Graphcore."
             The Eleventh International Conference on Learning Representations (ICLR). 2023.
          </li>
          <li>
            Wujin Li, Jiawei Zhan, <strong>Jinbao Wang</strong>‚Ä†, Bizhong Xia, Bin-Bin Gao, Jun Liu, Chengjie Wang, and Feng Zheng‚Ä†. 
            "Towards continual adaptation in industrial anomaly detection." 
            In Proceedings of the 30th ACM International Conference on Multimedia (ACM MM), pp. 2871-2880. 2022.
          </li>
          <li>
            Xi, Jiang, Jianlin Liu, <strong>Jinbao Wang</strong>‚Ä†, Qiang Nie, W. U. Kai, Yong Liu, Chengjie Wang, and Feng Zheng‚Ä†. 
            "SoftPatch: Unsupervised anomaly detection with noisy data." 
            In Advances in Neural Information Processing Systems (NeurIPS). 2022.
          </li>
          <li>
            <strong>Jinbao Wang</strong>*, Guoyang Xie*, Yawen Huang*, Yefeng Zheng, Yaochu Jin, and Feng Zheng. 
            "FedMed-ATL: Misaligned unpaired cross-modality neuroimage synthesis via affine transform loss." 
            In Proceedings of the 30th ACM International Conference on Multimedia (ACM MM), pp. 1522-1531. 2022.
          </li>
          <li>
            Hongjun Chen, <strong>Jinbao Wang</strong>, Hong Cai Chen, Xiantong Zhen, Feng Zheng, Rongrong Ji, and Ling Shao. 
            "Seminar learning for click-level weakly supervised semantic segmentation." 
            In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 6920-6929. 2021.
          </li>
          <li>
            Lian Chen, Ke Lu, Pengcheng Gao, Jian Xue, and <strong>Jinbao Wang</strong>. 
            "A novel multi-feature skeleton representation for 3d action recognition." 
            In International Conference on Pattern Recognition (ICPR), pp. 365-379. Springer, Cham, 2021.
          </li>
          <li>
            <strong>Jinbao Wang</strong>, Ke Lu, Jian Xue, and Yutong Kou. 
            "Relative depth estimation prior for single image dehazing." 
            In 2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW), pp. 270-275. IEEE, 2019.
          </li>
          <li>
            <strong>Jinbao Wang</strong>, Ke Lu, Jian Xue, Pengcheng Gao, and Yanfu Yan. 
            "A markerless body motion capture system for character animation based on multi-view cameras." 
            In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 8558-8562. IEEE, 2019.
          </li>
          <li>
            <strong>Jinbao Wang</strong>, Ning He, and Ke Lu. 
            "A new single image dehazing method with MSRCR algorithm." 
            In Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, pp. 1-4. 2015.
          </li>
          <li>
            Ning He, Ke Lu, and <strong>Jinbao Wang</strong>. 
            "Image denoising using fractional-order non-local TV model." 
            In Proceedings of International Conference on Internet Multimedia Computing and Service, pp. 279-282. 2014.
          </li>
        </ol>

        <p><b>Journal</b></p>
        <ol>
          <li>
            <strong>Jinbao Wang</strong>*, Guoyang Xie*, Yawen Huang*, Jiayi Lyu, Feng Zheng, Yefeng Zheng, and Yaochu Jin. 
            "K-space-aware cross-modality score for synthesized neuroimage quality assessment." 
            IEEE Journal of Biomedical and Health Informatics (IEEE JBHI) (Under Review). 2023. 
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221020">IF</a>
          </li>
          <li>
            Guoyang Xie*, <strong>Jinbao Wang</strong>*, Yawen Huang*, Jiayi Lyu, Feng Zheng, Yefeng Zheng, and Yaochu Jin. 
            "Cross-modality neuroimage synthesis: A survey." 
            ACM Computing Surveys (Major Revision). 2023. 
            <a href="https://dl.acm.org/journal/csur">IF</a>
          </li>
          <li>
            Guoyang Xie*, <strong>Jinbao Wang</strong>*, Jiaqi Liu*, Jiayi Lyu, Yong Liu, Chengjie Wang, Feng Zheng, and Yaochu Jin. 
            "IM-IAD: Industrial image anomaly detection benchmark in manufacturing." 
            IEEE Transactions on Cybernetics (IEEE TCYB) (Major Revision). 2023. 
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">IF</a>
          </li>
          <li>
            Jiaqi Liu*, Guoyang Xie*, <strong>Jinbao Wang</strong>*, Shangnian Li, Chengjie Wang, Feng Zheng, and Yaochu Jin. 
            "Deep industrial image anomaly detection: A survey." 
            Machine Intelligence Research (MIR). 2023. 
            <a href="https://www.springer.com/journal/11633">IF</a>
          </li>
          <li>
            Guoyang Xie*, <strong>Jinbao Wang</strong>*, Guo Yu, Feng Zheng, and Yaochu Jin. 
            "Tiny adversarial mulit-objective oneshot neural architecture search." 
            Complex & Intelligent Systems (CIS) 6 (2023): 107-109. 
            <a href="https://www.springer.com/journal/40747">IF</a>
          </li>
          <li>
            <strong>Jinbao Wang</strong>*, Xie, Guoyang*, Yawen Huang*, Jiayi Lyu, Feng Zheng, Yefeng Zheng, and Yaochu Jin. 
            "FedMed-GAN: Federated domain translation on unsupervised cross-modality brain image synthesis." 
            Neurocomputing 546 (2023): 126282. 
            <a href="https://www.sciencedirect.com/journal/neurocomputing">IF</a>
          </li>
          <li>
            Hao Zheng*, <strong>Jinbao Wang</strong>*, Xiantong Zhen, Jingkuan Song, Feng Zheng, Ke Lu, and Guo-Jun Qi. 
            "Continuous cross-modal hashing." 
            Pattern Recognition (PR) 142 (2023): 109662. 
            <a href="https://www.sciencedirect.com/journal/pattern-recognition">IF</a>
          </li>
          <li>
            <strong>Jinbao Wang</strong>, Shuo Xu, Feng Zheng, Ke Lu, Jingkuan Song, and Ling Shao. 
            "Learning efficient hash codes for fast graph-based data similarity retrieval. 
            "IEEE Transactions on Image Processing (IEEE TIP) 30 (2021): 6321-6334. 
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IF</a>
          </li>
          <li>
            <strong>Jinbao Wang</strong>*, Shujie Tan*, Xiantong Zhen, Shuo Xu, Feng Zheng, Zhenyu He, and Ling Shao. 
            "Deep 3D human pose estimation: A review." 
            Computer Vision and Image Understanding (CVIU) 210 (2021): 103225. 
            <a href="https://www.sciencedirect.com/journal/computer-vision-and-image-understanding">IF</a>
          </li>
          <li>
            <strong>Jinbao Wang</strong>, Ke Lu, Jian Xue, Ning He, and Ling Shao. 
            "Single image dehazing based on the physical model and MSRCR algorithm." 
            IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT) 28, no. 9 (2017): 2190-2199. 
            <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IF</a>
          </li>
          <li>
            <strong>Jinbao Wang</strong>, Ning He, Lu-Lu Zhang, and Ke Lu. 
            "Single image dehazing with a physical model and dark channel prior." 
            Neurocomputing 149 (2015): 718-728. 
            <a href="https://www.sciencedirect.com/journal/neurocomputing">IF</a>
          </li>
          <li>
            Ning He, <strong>Jinbao Wang</strong>, Lu-Lu Zhang, and Ke Lu. 
            "An improved fractional-order differentiation model for image denoising." 
            Signal Processing 112 (2015): 180-188. 
            <a href="https://www.sciencedirect.com/journal/signal-processing">IF</a>
          </li>
          <li>
            Ning He, <strong>Jinbao Wang</strong>, Lu-Lu Zhang, Guang-Mei Xu, and Ke Lu. 
            "Non-local sparse regularization model with application to image denoising." 
            Multimedia Tools and Applications 75, no. 5 (2016): 2579-2594. 
            <a href="https://www.springer.com/journal/11042">IF</a>
          </li>
          <li>
            Ning He, <strong>Jinbao Wang</strong>, Lu-Lu Zhang, and Ke Lu. 
            "Convex optimization based low-rank matrix decomposition for image restoration." 
            Neurocomputing 172 (2016): 253-261. 
            <a href="https://www.sciencedirect.com/journal/neurocomputing">IF</a>
          </li>
          <li>
            Ning He, Ke Lu, Bing-Kun Bao, Lu-Lu Zhang, and <strong>Jinbao Wang</strong>. 
            "Single-image motion deblurring using an adaptive image prior." 
            Information Sciences 281 (2014): 736-749. 
            <a href="https://www.springer.com/journal/11042">IF</a>
          </li>
        </ol>
      </td>
    </tr>
  </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>	
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. Thanks to <a href="https://jonbarron.info">JonBarron</a>. 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
